{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF5rsS1sdMIO"
      },
      "source": [
        "OPTIMIZE = False\n",
        "TRAIN = False\n",
        "TRAIN_EPOCHS = 40  # number of epochs for training\n",
        "OPTIM_EPOCHS = 5  # number of epochs for optimization"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdYowWlEpqGa"
      },
      "source": [
        "!pip install optuna &> /dev/null"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86Cda0u0jDWe"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import optuna\n",
        "import json"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSxYCxPmnha4"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        torch.manual_seed(14)\n",
        "        self.classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "                        'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "        # conv layers\n",
        "        self.conv1 = nn.Conv2d(3, 48, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(48, 96, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(96, 192, 3, padding=1)\n",
        "        self.conv4 = nn.Conv2d(192, 256, 3, padding=1)\n",
        "        # maxpool and drop\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.drop = nn.Dropout(0.2)\n",
        "        # batch normalizations\n",
        "        self.batchnorm2d1 = nn.BatchNorm2d(48)\n",
        "        self.batchnorm2d2 = nn.BatchNorm2d(96)\n",
        "        self.batchnorm2d3 = nn.BatchNorm2d(192)\n",
        "        self.batchnorm2d4 = nn.BatchNorm2d(256)\n",
        "        self.batchnorm1d1 = nn.BatchNorm1d(1500)\n",
        "        self.batchnorm1d2 = nn.BatchNorm1d(750)\n",
        "        self.batchnorm1d3 = nn.BatchNorm1d(300)\n",
        "        self.batchnorm1d4 = nn.BatchNorm1d(100)\n",
        "        self.batchnorm1d5 = nn.BatchNorm1d(50)\n",
        "        # fully connected layers\n",
        "        self.fc1 = nn.Linear(256*8*8, 1500)\n",
        "        self.fc2 = nn.Linear(1500, 750)\n",
        "        self.fc3 = nn.Linear(750, 300)\n",
        "        self.fc4 = nn.Linear(300, 100)\n",
        "        self.fc5 = nn.Linear(100, 50)\n",
        "        self.fc6 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x  # input layer\n",
        "\n",
        "        x = self.batchnorm2d1(self.conv1(x))\n",
        "        x = F.relu(x)\n",
        "        x = self.batchnorm2d2(self.conv2(x))\n",
        "        x = F.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.batchnorm2d3(self.conv3(x))\n",
        "        x = F.relu(x)\n",
        "        x = self.batchnorm2d4(self.conv4(x))\n",
        "        x = F.relu(x)\n",
        "        x = self.pool2(x)\n",
        "        x = self.drop(x)\n",
        "        x = x.view(-1, 256*8*8)\n",
        "        x = self.batchnorm1d1(self.fc1(x))\n",
        "        x = F.relu(x)\n",
        "        x = self.batchnorm1d2(self.fc2(x))\n",
        "        x = F.relu(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.batchnorm1d3(self.fc3(x))\n",
        "        x = F.relu(x)\n",
        "        x = self.batchnorm1d4(self.fc4(x))\n",
        "        x = F.relu(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.batchnorm1d5(self.fc5(x))\n",
        "        x = F.relu(self.fc6(x))\n",
        "        # torch.nnCrossEntropyLoss() contain nn.LogSoftmax()\n",
        "        # so there is no need to use softmax\n",
        "        return x\n",
        "\n",
        "    def fit(self, train_loader, optimizer, epochs, device='cpu', valid_loader=None, verbose=5):\n",
        "        '''\n",
        "            verbose is number of batch report prints for epoch. For example\n",
        "            verbose=0 will not print any batch reports, whereas verbose=5 will\n",
        "            print 5 batch reports per epoch.\n",
        "        '''\n",
        "\n",
        "        assert epochs > 0, \"epochs cannot be smaller then 1\"\n",
        "        self.to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        valid_accuracies = []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = []          # Array of losses in epoch\n",
        "            correct_predictions = 0  # Number of correct predictions made in validation\n",
        "            total_predictions = 0    # Number of total predictions made in validation\n",
        "\n",
        "            for i, data in enumerate(train_loader):\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = self(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                epoch_loss.append(loss.item())\n",
        "\n",
        "                # torch.linspace() is creating 1d tensor with even spaces in between, after removing first and last values\n",
        "                # we have wanted amount of evenly spaced values between two boundaries\n",
        "                if i in torch.linspace(0, len(train_loader), verbose+2, dtype=torch.int32)[1:-1] and verbose != 0:\n",
        "                    # This is batch report print\n",
        "                    print(f'Epoch {epoch+1:3}, Batch {i+1:5}, loss {loss.item():.5f}')\n",
        "\n",
        "            if valid_loader is not None:\n",
        "                self.eval()\n",
        "                with torch.no_grad():\n",
        "                    for data in valid_loader:\n",
        "                        images, labels = data\n",
        "                        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                        outputs = self(images)\n",
        "                        _, predicted = torch.max(outputs, 1)\n",
        "                        c = (predicted == labels).squeeze()\n",
        "                        total_predictions += len(c)\n",
        "                        correct_predictions += c.sum()\n",
        "                self.train()\n",
        "\n",
        "            valid_accuracy = (correct_predictions / total_predictions) * 100\n",
        "            valid_accuracies.append(valid_accuracy)\n",
        "\n",
        "            valid_result = f', Validation Accuracy {valid_accuracy:6.2f}' if valid_loader is not None else ''\n",
        "            print(f'Epoch {epoch+1:3}, loss {sum(epoch_loss) / len(epoch_loss):.5f}{valid_result}\\n')\n",
        "\n",
        "        return max(valid_accuracies)\n",
        "\n",
        "    def test(self, test_loader, device='cpu'):\n",
        "        '''\n",
        "            Returns to a dictionary that contains the both\n",
        "            categorical and total accuracies\n",
        "        '''\n",
        "        self.eval()\n",
        "        self.to(device)\n",
        "\n",
        "        class_correct = list(0. for i in range(10))\n",
        "        class_total = list(0. for i in range(10))\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in test_loader:\n",
        "                images, labels = data\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs = self(images)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                c = (predicted == labels).squeeze()\n",
        "                for i in range(len(images)):\n",
        "                    label = labels[i]\n",
        "                    class_correct[label] += c[i].item()\n",
        "                    class_total[label] += 1\n",
        "\n",
        "        self.train()\n",
        "\n",
        "        for i in range(10):\n",
        "            print(f'Accuracy of {self.classes[i]:5}: {100 * (class_correct[i]/class_total[i]):6.2f}%')\n",
        "        print(f'Total accuracy is: {100 * (sum(class_correct)/sum(class_total)):6.2f}%')\n",
        "\n",
        "    def save(self, path='cifar10-1.pth'):\n",
        "        torch.save(self.state_dict(), path)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfFLpMwWnk1a"
      },
      "source": [
        "class DataPrep:\n",
        "\n",
        "    def __init__(self, batch_size=32):\n",
        "        self.transform = transforms.Compose([transforms.RandomCrop(32, 5,\n",
        "                                            padding_mode='reflect'),\n",
        "                                            transforms.RandomHorizontalFlip(),\n",
        "                                            transforms.RandomRotation(10),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n",
        "\n",
        "        train_data = torchvision.datasets.CIFAR10(root='./data/cifar10-train', train=True,\n",
        "                                                  download=True, transform=self.transform)\n",
        "        test_data = torchvision.datasets.CIFAR10(root='./data/cifar10-test', train=False,\n",
        "                                                 download=True, transform=self.transform)\n",
        "\n",
        "        train_dataset, vald_dataset = torch.utils.data.random_split(train_data, [40000, 10000])\n",
        "        __, mini_data = torch.utils.data.random_split(train_data, [45000, 5000])\n",
        "        train_mini, vald_mini = torch.utils.data.random_split(mini_data, [4000, 1000])\n",
        "\n",
        "        self.train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        self.valid_loader = torch.utils.data.DataLoader(vald_dataset, batch_size=batch_size, shuffle=True)\n",
        "        self.test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "        self.train_mini_loader = torch.utils.data.DataLoader(train_mini, batch_size=batch_size, shuffle=True)\n",
        "        self.vald_mini_loader = torch.utils.data.DataLoader(vald_mini, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    def get_train_loader(self):\n",
        "        return self.train_loader\n",
        "\n",
        "    def get_valid_loader(self):\n",
        "        return self.valid_loader\n",
        "\n",
        "    def get_test_loader(self):\n",
        "        return self.test_loader\n",
        "\n",
        "    def get_train_mini_loader(self):\n",
        "        return self.train_mini_loader\n",
        "\n",
        "    def get_vald_mini_loader(self):\n",
        "        return self.vald_mini_loader\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj9DirNDnoUn"
      },
      "source": [
        "class OptunaOptimizer():\n",
        "\n",
        "    def __init__(self, train_loader, vald_loader, n_trials=100, epochs=1, device='cpu'):\n",
        "        self.train_loader = train_loader\n",
        "        self.vald_loader = vald_loader\n",
        "        self.n_trials = n_trials\n",
        "        self.epochs = epochs\n",
        "        self.device = device\n",
        "        self.study = optuna.create_study(direction='maximize')\n",
        "        self.study.optimize(self.objective, n_trials=self.n_trials)\n",
        "        self.best_params = self.study.best_params\n",
        "        self.write_to_json(self.best_params)\n",
        "\n",
        "    def objective(self, trial):\n",
        "        model = Net()\n",
        "\n",
        "        optimizer = trial.suggest_categorical('optimizer', ['Adam', 'AdamW', 'ASGD', 'SGD'])\n",
        "        lr = trial.suggest_loguniform('lr', 1e-7, 1e-3)\n",
        "\n",
        "        if optimizer == 'Adam':\n",
        "            beta1 = trial.suggest_float('beta1', 0.7, 1)\n",
        "            beta2 = trial.suggest_float('beta2', 0.7, 1)\n",
        "            weight_decay = trial.suggest_float('weight_decay', 0, 1e-1)\n",
        "            epsilon = trial.suggest_float('epsilon', 0, 1e-5)\n",
        "            optimizer = optim.Adam(model.parameters(), lr=lr, betas=(beta1, beta2), eps=epsilon, weight_decay=weight_decay)\n",
        "        elif optimizer == 'AdamW':\n",
        "            beta1 = trial.suggest_float('beta1', 0.7, 1)\n",
        "            beta2 = trial.suggest_float('beta2', 0.7, 1)\n",
        "            epsilon = trial.suggest_float('epsilon', 0, 1e-5)\n",
        "            weight_decay = trial.suggest_float('weight_decay', 0, 1e-1)\n",
        "            optimizer = optim.AdamW(model.parameters(), lr=lr, betas=(beta1, beta2), eps=epsilon, weight_decay=weight_decay)\n",
        "        elif optimizer == 'ASGD':\n",
        "            lambd = trial.suggest_float('lambd', 0, 1e-6)\n",
        "            alpha = trial.suggest_float('alpha', 0.5, 1)\n",
        "            t0 = trial.suggest_float('t0', 0, 1e-4)\n",
        "            weight_decay = trial.suggest_float('weight_decay', 1e-7, 1e-1)\n",
        "            optimizer = optim.ASGD(model.parameters(), lr=lr, lambd=lambd, alpha=alpha, t0=t0, weight_decay=weight_decay)\n",
        "        elif optimizer == 'SGD':\n",
        "            momentum = trial.suggest_float('momentum', 0.7, 1)\n",
        "            weight_decay = trial.suggest_float('weight_decay', 1e-7, 1e-1)\n",
        "            dampening = trial.suggest_float('dampening', 0, 1e-1)\n",
        "            optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, dampening=dampening, weight_decay=weight_decay)\n",
        "\n",
        "        accuracy = model.fit(self.train_loader, optimizer, self.epochs, device=self.device, valid_loader=self.vald_loader, verbose=0)\n",
        "        del model\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "    def write_to_json(self, params):\n",
        "        with open('./src/params.json', 'w') as json_file:\n",
        "            json.dump(params, json_file)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwkbSOKYnxE-",
        "outputId": "deabfe03-e68d-4604-d33b-fb918c9b766c"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "data_loaders = DataPrep()\n",
        "train_loader = data_loaders.get_train_loader()\n",
        "valid_loader = data_loaders.get_valid_loader()\n",
        "test_loader = data_loaders.get_test_loader()\n",
        "train_mini_loader = data_loaders.get_train_mini_loader()\n",
        "vald_mini_loader = data_loaders.get_vald_mini_loader()\n",
        "\n",
        "model = Net()\n",
        "\n",
        "if OPTIMIZE:\n",
        "    optuna_opt = OptunaOptimizer(train_mini_loader, vald_mini_loader, epochs=OPTIM_EPOCHS, device=device)\n",
        "    params = optuna_opt.best_params\n",
        "else:\n",
        "    with open('params.json') as f:\n",
        "        params = json.load(f)\n",
        "\n",
        "if TRAIN:\n",
        "    if params['optimizer'] == 'Adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=params['lr'], betas=(params['beta1'], params['beta2']), eps=params['epsilon'], weight_decay=params['weight_decay'])\n",
        "    elif params['optimizer'] == 'AdamW':\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=params['lr'], betas=(params['beta1'], params['beta2']), eps=params['epsilon'], weight_decay=params['weight_decay'])\n",
        "    elif params['optimizer'] == 'ASGD':\n",
        "        optimizer = optim.ASGD(model.parameters(), lr=params['lr'], lambd=params['lambd'], alpha=params['alpha'], t0=params['t0'], weight_decay=params['weight_decay'])\n",
        "    elif params['optimizer'] == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=params['lr'], momentum=params['momentum'], dampening=params['dampening'], weight_decay=params['weight_decay'])\n",
        "\n",
        "    model.fit(train_loader, optimizer, TRAIN_EPOCHS, device=device, valid_loader=valid_loader, verbose=3)\n",
        "    model.save()\n",
        "else:\n",
        "    model.load_state_dict(torch.load('cifar10-1.pth'))\n",
        "\n",
        "model.test(test_loader, device=device)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Accuracy of plane:  86.30%\n",
            "Accuracy of car  :  91.50%\n",
            "Accuracy of bird :  80.00%\n",
            "Accuracy of cat  :  70.30%\n",
            "Accuracy of deer :  84.60%\n",
            "Accuracy of dog  :  75.30%\n",
            "Accuracy of frog :  89.10%\n",
            "Accuracy of horse:  82.80%\n",
            "Accuracy of ship :  91.90%\n",
            "Accuracy of truck:  92.80%\n",
            "Total accuracy is:  84.46%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}